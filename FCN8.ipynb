{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Input, Activation, MaxPooling2D, Add, BatchNormalization, Reshape\n",
    "from keras.models import Model\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "from scipy.misc import imread, imresize\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (160,480,3)\n",
    "vgg = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reference for model architecture: https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf\n",
    "def get_FCN8(num_classes):\n",
    "    custom_init = TruncatedNormal(stddev=0.01)\n",
    "\n",
    "    # Get the block 3 pooling layer from VGG\n",
    "    pool3 = vgg.get_layer('block3_pool').output\n",
    "\n",
    "    # Get the block 4 pooling layer from VGG\n",
    "    pool4 = vgg.get_layer('block4_pool').output\n",
    "\n",
    "    # Get the block 5 pooling layer from VGG\n",
    "    pool5 = vgg.get_layer('block5_pool').output\n",
    "\n",
    "    fc6 = Conv2D(4096, (7,7), kernel_initializer = custom_init,\n",
    "               kernel_regularizer = regularizers.l2(0.01), padding='Same')(pool5)\n",
    "\n",
    "    fc7 = Conv2D(4096, (1,1), kernel_initializer = custom_init,\n",
    "               kernel_regularizer = regularizers.l2(0.01), padding='Same')(fc6)\n",
    "\n",
    "    layer_7_1x1 = (Conv2D(num_classes, (1,1), kernel_initializer = custom_init,\n",
    "                 kernel_regularizer = regularizers.l2(0.01), padding='Same'))(fc7)\n",
    "    upsample1 = (Conv2DTranspose(num_classes, (4,4), strides = 2, kernel_initializer = custom_init,\n",
    "               kernel_regularizer = regularizers.l2(0.01), padding='Same'))(layer_7_1x1)\n",
    "    x = (BatchNormalization(axis=1))(upsample1)\n",
    "    layer_4_1x1 = (Conv2D(num_classes, (1,1), kernel_initializer = custom_init,\n",
    "                        kernel_regularizer = regularizers.l2(0.01), padding='Same'))(pool4)\n",
    "    x = Add()([x, layer_4_1x1])\n",
    "    upsample2 = (Conv2DTranspose(num_classes, (4,4), strides = 2, kernel_initializer = custom_init,\n",
    "                               kernel_regularizer = regularizers.l2(0.01), padding='Same'))(x)\n",
    "    x = (BatchNormalization(axis=1))(upsample2)\n",
    "    layer_3_1x1 = (Conv2D(num_classes, (1,1), kernel_initializer = custom_init,\n",
    "                        kernel_regularizer = regularizers.l2(0.01), padding='Same'))(pool3)\n",
    "    x = Add()([x, layer_3_1x1])\n",
    "    upsample3 = (Conv2DTranspose(num_classes, (16,16), strides = 8, kernel_initializer = custom_init,\n",
    "                               kernel_regularizer = regularizers.l2(0.01), padding='Same'))(x)\n",
    "\n",
    "    out_layer = (Activation('softmax'))(upsample3)\n",
    "\n",
    "    model = Model(vgg.get_layer('input_1').output, out_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 160, 480, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 160, 480, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 160, 480, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 80, 240, 64)  0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 80, 240, 128) 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 80, 240, 128) 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 40, 120, 128) 0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 40, 120, 256) 295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 40, 120, 256) 590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 40, 120, 256) 590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 20, 60, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 20, 60, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 20, 60, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 20, 60, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 10, 30, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 10, 30, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 10, 30, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 10, 30, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 5, 15, 512)   0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 5, 15, 4096)  102764544   block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 5, 15, 4096)  16781312    conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 5, 15, 2)     8194        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 10, 30, 2)    66          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 10, 30, 2)    40          conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 10, 30, 2)    1026        block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 10, 30, 2)    0           batch_normalization_1[0][0]      \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 20, 60, 2)    66          add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 20, 60, 2)    80          conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 20, 60, 2)    514         block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 20, 60, 2)    0           batch_normalization_2[0][0]      \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 160, 480, 2)  1026        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 160, 480, 2)  0           conv2d_transpose_3[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 134,271,556\n",
      "Trainable params: 134,271,496\n",
      "Non-trainable params: 60\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fcn8 = get_FCN8(2)\n",
    "fcn8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the Model\n",
    "adam = Adam(lr = 0.001)\n",
    "fcn8.compile(optimizer=adam,\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = 'data_road/training'\n",
    "\n",
    "training_images = glob(os.path.join(data_folder, 'image_2', '*.png'))\n",
    "num_samples = len(training_images)\n",
    "num_training = int(num_samples*0.8)\n",
    "\n",
    "\n",
    "def training_generator(data_folder, image_shape, batch_size, training = True):\n",
    "    image_paths = glob(os.path.join(data_folder, 'image_2', '*.png'))[:num_training]\n",
    "    label_paths = {re.sub(r'_(lane|road)_', '_', os.path.basename(path)): path\n",
    "        for path in glob(os.path.join(data_folder, 'gt_image_2', '*_road_*.png'))}\n",
    "    background_color = np.array([255, 0, 0])\n",
    "    while 1:\n",
    "        random.shuffle(image_paths)\n",
    "        for batch_i in range(0, len(image_paths), batch_size):\n",
    "            images = []\n",
    "            gt_images = []\n",
    "            for image_file in image_paths[batch_i:batch_i+batch_size]:\n",
    "                gt_image_file = label_paths[os.path.basename(image_file)]\n",
    "\n",
    "                image = imresize(imread(image_file), image_shape)\n",
    "                gt_image = imresize(imread(gt_image_file), image_shape)\n",
    "\n",
    "                gt_bg = np.all(gt_image == background_color, axis=2)\n",
    "                gt_bg = np.expand_dims(gt_bg, axis=2)\n",
    "                gt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)\n",
    "\n",
    "                images.append(image)\n",
    "                gt_images.append(gt_image)\n",
    "\n",
    "            yield np.array(images), np.array(gt_images)\n",
    "            \n",
    "def validation_generator(data_folder, image_shape, batch_size, training = True):\n",
    "\n",
    "    image_paths = glob(os.path.join(data_folder, 'image_2', '*.png'))[num_training:]\n",
    "    label_paths = {re.sub(r'_(lane|road)_', '_', os.path.basename(path)): path\n",
    "        for path in glob(os.path.join(data_folder, 'gt_image_2', '*_road_*.png'))}\n",
    "    background_color = np.array([255, 0, 0])\n",
    "    while 1:\n",
    "        random.shuffle(image_paths)\n",
    "        for batch_i in range(0, len(image_paths), batch_size):\n",
    "            images = []\n",
    "            gt_images = []\n",
    "            for image_file in image_paths[batch_i:batch_i+batch_size]:\n",
    "                gt_image_file = label_paths[os.path.basename(image_file)]\n",
    "\n",
    "                image = imresize(imread(image_file), image_shape)\n",
    "                gt_image = imresize(imread(gt_image_file), image_shape)\n",
    "\n",
    "                gt_bg = np.all(gt_image == background_color, axis=2)\n",
    "                gt_bg = np.expand_dims(gt_bg, axis=2)\n",
    "                gt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)\n",
    "\n",
    "                images.append(image)\n",
    "                gt_images.append(gt_image)\n",
    "\n",
    "            yield np.array(images), np.array(gt_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('fcn8_weights.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "batch_size=8\n",
    "train_generator = training_generator('data_road/training', (160,480), batch_size=batch_size)\n",
    "val_generator = validation_generator('data_road/training', (160,480), batch_size=batch_size, training=False)\n",
    "fcn8_history = fcn8.fit_generator(train_generator, steps_per_epoch = num_training//batch_size,\n",
    "                    epochs = 25, verbose = 1, validation_data = val_generator,\n",
    "                    validation_steps = (num_samples - num_training)//batch_size, callbacks=[checkpoint],\n",
    "                                   initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(fcn8_history.history['val_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_image = imresize(imread('data_road/testing/image_2/um_000000.png'), (160,480))\n",
    "plt.grid('off')\n",
    "plt.imshow(test_image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = fcn8.predict(test_image.reshape(1,160,480,3))\n",
    "mask = np.dstack((np.zeros_like(pred[0,:,:,0]),\n",
    "                 np.round(pred[0,:,:,1]),\n",
    "                 np.zeros_like(pred[0,:,:,0])))\n",
    "plt.grid('off')\n",
    "plt.imshow(mask.astype('uint8')*255);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = cv2.addWeighted(test_image, 1.0, mask.astype('uint8')*255, 0.6, 0)\n",
    "plt.grid('off')\n",
    "plt.imshow(output);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_image = imresize(imread('data_road/testing/image_2/umm_000002.png'), (160,480))\n",
    "plt.grid('off')\n",
    "plt.imshow(test_image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = fcn8.predict(test_image.reshape(1,160,480,3))\n",
    "mask = np.dstack((np.zeros_like(pred[0,:,:,0]),\n",
    "                 np.round(pred[0,:,:,1]),\n",
    "                 np.zeros_like(pred[0,:,:,0])))\n",
    "plt.grid('off')\n",
    "plt.imshow(mask.astype('uint8')*255);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = cv2.addWeighted(test_image, 1.0, mask.astype('uint8')*255, 0.6, 0)\n",
    "plt.grid('off')\n",
    "plt.imshow(output);"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
