{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Input, Activation, MaxPooling2D, Add, BatchNormalization, Reshape\n",
    "from keras.models import Model\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "from scipy.misc import imread, imresize\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download the pretrained VGG16 network\n",
    "input_shape = (160,480,3)\n",
    "vgg = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reference for model architecture: https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf\n",
    "def get_FCN32(num_classes):\n",
    "    # Define a custom intializer\n",
    "    custom_init = TruncatedNormal(stddev=0.01)\n",
    "    \n",
    "    ## Get the block 5 pooling layer from VGG\n",
    "    pool5 = vgg.get_layer('block5_pool').output\n",
    "\n",
    "    # Create a convolutionalized version of the first fully connected layer\n",
    "    fc6 = Conv2D(4096, (7,7), kernel_initializer = custom_init,\n",
    "               kernel_regularizer = regularizers.l2(0.01), padding='Same')(pool5)\n",
    "\n",
    "    # Create a convolutionalized version of the second fully connected layer\n",
    "    fc7 = Conv2D(4096, (1,1), kernel_initializer = custom_init,\n",
    "               kernel_regularizer = regularizers.l2(0.01), padding='Same')(fc6)\n",
    "\n",
    "    # Apply a 1x1 onvolution and upsample to the original image shape\n",
    "    layer_7_1x1 = Conv2D(num_classes, (1,1), kernel_initializer = custom_init,\n",
    "                 kernel_regularizer = regularizers.l2(0.01), padding='Same')(fc7)\n",
    "    upsample1 = Conv2DTranspose(num_classes, (64,64), strides = 32, kernel_initializer = custom_init,\n",
    "               kernel_regularizer = regularizers.l2(0.01), padding='Same')(layer_7_1x1)\n",
    "\n",
    "    # Add softmax activation\n",
    "    out_layer = (Activation('softmax'))(upsample1)\n",
    "\n",
    "    model = Model(vgg.get_layer('input_1').output, out_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 160, 480, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 160, 480, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 160, 480, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 80, 240, 64)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 80, 240, 128)      73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 80, 240, 128)      147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 40, 120, 128)      0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 40, 120, 256)      295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 40, 120, 256)      590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 40, 120, 256)      590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 20, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 20, 60, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 20, 60, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 20, 60, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 10, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 10, 30, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 10, 30, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 10, 30, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 5, 15, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 5, 15, 4096)       102764544 \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 5, 15, 4096)       16781312  \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 15, 2)          8194      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 160, 480, 2)       16386     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 160, 480, 2)       0         \n",
      "=================================================================\n",
      "Total params: 134,285,124\n",
      "Trainable params: 134,285,124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fcn32 = get_FCN32(2)\n",
    "fcn32.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the Model\n",
    "adam = Adam(lr = 0.001)\n",
    "fcn32.compile(optimizer=adam,\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = 'data_road/training'\n",
    "\n",
    "training_images = glob(os.path.join(data_folder, 'image_2', '*.png'))\n",
    "num_samples = len(training_images)\n",
    "num_training = int(num_samples*0.8)\n",
    "\n",
    "\n",
    "def train_generator(data_folder, image_shape, batch_size, training = True):\n",
    "    image_paths = glob(os.path.join(data_folder, 'image_2', '*.png'))[:num_training]\n",
    "    label_paths = {re.sub(r'_(lane|road)_', '_', os.path.basename(path)): path\n",
    "        for path in glob(os.path.join(data_folder, 'gt_image_2', '*_road_*.png'))}\n",
    "    background_color = np.array([255, 0, 0])\n",
    "    while 1:\n",
    "        random.shuffle(image_paths)\n",
    "        for batch_i in range(0, len(image_paths), batch_size):\n",
    "            images = []\n",
    "            gt_images = []\n",
    "            for image_file in image_paths[batch_i:batch_i+batch_size]:\n",
    "                gt_image_file = label_paths[os.path.basename(image_file)]\n",
    "\n",
    "                image = imresize(imread(image_file), image_shape)\n",
    "                gt_image = imresize(imread(gt_image_file), image_shape)\n",
    "\n",
    "                gt_bg = np.all(gt_image == background_color, axis=2)\n",
    "                gt_bg = np.expand_dims(gt_bg, axis=2)\n",
    "                gt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)\n",
    "\n",
    "                images.append(image)\n",
    "                gt_images.append(gt_image)\n",
    "\n",
    "            yield np.array(images), np.array(gt_images)\n",
    "            \n",
    "def val_generator(data_folder, image_shape, batch_size, training = True):\n",
    "\n",
    "    image_paths = glob(os.path.join(data_folder, 'image_2', '*.png'))[num_training:]\n",
    "    label_paths = {re.sub(r'_(lane|road)_', '_', os.path.basename(path)): path\n",
    "        for path in glob(os.path.join(data_folder, 'gt_image_2', '*_road_*.png'))}\n",
    "    background_color = np.array([255, 0, 0])\n",
    "    while 1:\n",
    "        random.shuffle(image_paths)\n",
    "        for batch_i in range(0, len(image_paths), batch_size):\n",
    "            images = []\n",
    "            gt_images = []\n",
    "            for image_file in image_paths[batch_i:batch_i+batch_size]:\n",
    "                gt_image_file = label_paths[os.path.basename(image_file)]\n",
    "\n",
    "                image = imresize(imread(image_file), image_shape)\n",
    "                gt_image = imresize(imread(gt_image_file), image_shape)\n",
    "\n",
    "                gt_bg = np.all(gt_image == background_color, axis=2)\n",
    "                gt_bg = np.expand_dims(gt_bg, axis=2)\n",
    "                gt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)\n",
    "\n",
    "                images.append(image)\n",
    "                gt_images.append(gt_image)\n",
    "\n",
    "            yield np.array(images), np.array(gt_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('fcn32_weights.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "batch_size=8\n",
    "train_generator = train_generator('data_road/training', (160,480), batch_size=batch_size)\n",
    "val_generator = val_generator('data_road/training', (160,480), batch_size=batch_size, training=False)\n",
    "fcn32_history = fcn32.fit_generator(train_generator, steps_per_epoch = num_training//batch_size,\n",
    "                    epochs = 25, verbose = 1, validation_data = val_generator,\n",
    "                    validation_steps = (num_samples - num_training)//batch_size, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(fcn32_history.history['val_acc']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn32.load_weights('fcn32_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_image = imresize(imread('data_road/testing/image_2/um_000000.png'), (160,480))\n",
    "plt.grid('off')\n",
    "plt.imshow(test_image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = fcn32.predict(test_image.reshape(1,160,480,3))\n",
    "mask = np.dstack((np.zeros_like(pred[0,:,:,0]),\n",
    "                 np.round(pred[0,:,:,1]),\n",
    "                 np.zeros_like(pred[0,:,:,0])))\n",
    "plt.grid('off')\n",
    "plt.imshow(mask.astype('uint8')*255);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "output = cv2.addWeighted(test_image, 1.0, mask.astype('uint8')*255, 0.6, 0)\n",
    "plt.grid('off')\n",
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_image = imresize(imread('data_road/testing/image_2/umm_000002.png'), (160,480))\n",
    "plt.grid('off')\n",
    "plt.imshow(test_image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = fcn32.predict(test_image.reshape(1,160,480,3))\n",
    "mask = np.dstack((np.zeros_like(pred[0,:,:,0]),\n",
    "                 np.round(pred[0,:,:,1]),\n",
    "                 np.zeros_like(pred[0,:,:,0])))\n",
    "plt.grid('off')\n",
    "plt.imshow(mask.astype('uint8')*255);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = cv2.addWeighted(test_image, 1.0, mask.astype('uint8')*255, 0.6, 0)\n",
    "plt.grid('off')\n",
    "plt.imshow(output)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
